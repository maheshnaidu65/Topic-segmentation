{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_segmention_engine.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDA7yp0vsYEj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf_QbGLTslCw",
        "colab_type": "text"
      },
      "source": [
        "## A Topic Segmentation Engine for Segregating News Content into Categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7Gapzms0e3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   \tPre-processed a data set containing news articles belonging to different categories like Sports, Politics, Business etc.\n",
        "*   Built a classifier using multilayer LSTM to predict the category of the news content.\n",
        "\n",
        "*   Achieved accuracy of 90 percent on classification, using the multi-class confusion matrix.\n",
        "\n",
        "    The below steps descibe the programming methodology in detail\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PxfLZlBFk6U",
        "colab_type": "text"
      },
      "source": [
        "THe dataset consists of 2225 rows and two columns. Column 1 contains the news articles (textual data) and column 2 in the output variable taking values 1 -5 depending on the category of the news article in column 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9c0m738EqAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd                   #importing the dataset prepared by extracting the articles.. \n",
        "df = pd.read_pickle('topic_bbc_all')  # ..from all .txt files (steps explained in xyz.ipynb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivsN5huscL0",
        "colab_type": "text"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP8W1i1TpCMz",
        "colab_type": "code",
        "outputId": "9e39e5ea-0ed8-4279-cf20-6192f17d1b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "#function to remove a certain pattern in the text\n",
        "def remove_pattern(input_txt, pattern):  \n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, ' ', input_txt)\n",
        "        \n",
        "    return input_txt\n",
        "  \n",
        "df['Text'] = np.vectorize(remove_pattern)(df['Text'], \"\\n\")\n",
        "df['Text'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Ad sales boost Time Warner profit  Quarterly p...\n",
              "1    Dollar gains on Greenspan speech  The dollar h...\n",
              "2    Yukos unit buyer faces loan claim  The owners ...\n",
              "3    High fuel prices hit BA's profits  British Air...\n",
              "4    Pernod takeover talk lifts Domecq  Shares in U...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdiR7dZHtQ_N",
        "colab_type": "code",
        "outputId": "f6ff80f4-fc1d-4753-dd85-e78d5e13d075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Removing all characters beside alphabets and #\n",
        "df['Text'] = df['Text'].str.replace(\"[^a-zA-Z]\", \" \") \n",
        "df['Text'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Ad sales boost Time Warner profit  Quarterly p...\n",
              "1    Dollar gains on Greenspan speech  The dollar h...\n",
              "2    Yukos unit buyer faces loan claim  The owners ...\n",
              "3    High fuel prices hit BA s profits  British Air...\n",
              "4    Pernod takeover talk lifts Domecq  Shares in U...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rWl3mUtWRvs",
        "colab_type": "code",
        "outputId": "e4bd8244-9a18-4039-e4cc-6113d5dd2460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "\n",
        "df.groupby(['Label']).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>510</td>\n",
              "      <td>502</td>\n",
              "      <td>Singapore growth at      in       Singapore s ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>386</td>\n",
              "      <td>369</td>\n",
              "      <td>Famed music director Viotti dies  Conductor Ma...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>417</td>\n",
              "      <td>403</td>\n",
              "      <td>Schools to take part in mock poll  Record numb...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>511</td>\n",
              "      <td>505</td>\n",
              "      <td>Spain coach faces racism inquiry  Spain s Foot...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>401</td>\n",
              "      <td>347</td>\n",
              "      <td>Europe backs digital TV lifestyle  How people ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Text                                                               \n",
              "      count unique                                                top freq\n",
              "Label                                                                     \n",
              "0       510    502  Singapore growth at      in       Singapore s ...    2\n",
              "1       386    369  Famed music director Viotti dies  Conductor Ma...    2\n",
              "2       417    403  Schools to take part in mock poll  Record numb...    2\n",
              "3       511    505  Spain coach faces racism inquiry  Spain s Foot...    2\n",
              "4       401    347  Europe backs digital TV lifestyle  How people ...    2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQf0jzKGxv0i",
        "colab_type": "code",
        "outputId": "b2bfaec4-b321-431e-9dca-f3f34654c59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#removing stop words\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "#from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['Text'] = df['Text'].apply(lambda x: ' '.join(w for w in x.split() if not w in stop_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1-IewJRyxcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing words with length less than 3(these words have less strength )\n",
        "df['Text'] = df['Text'].apply(lambda x: ' '.join(w for w in x.split() if len(w)>3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO94oO-Az0Nc",
        "colab_type": "code",
        "outputId": "ce46b7f4-c6f2-4b17-ca5a-8c2df0898596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sales boost Time Warner profit Quarterly profi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dollar gains Greenspan speech dollar highest l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yukos unit buyer faces loan claim owners embat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High fuel prices profits British Airways blame...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pernod takeover talk lifts Domecq Shares drink...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Label\n",
              "0  sales boost Time Warner profit Quarterly profi...      0\n",
              "1  Dollar gains Greenspan speech dollar highest l...      0\n",
              "2  Yukos unit buyer faces loan claim owners embat...      0\n",
              "3  High fuel prices profits British Airways blame...      0\n",
              "4  Pernod takeover talk lifts Domecq Shares drink...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ffl28ON2x5h",
        "colab_type": "code",
        "outputId": "8d6da012-ebf5-4a34-99d2-70a4e0eb18a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Stemmming - to have a single word for words having the same meaning but used in different forms like play, playing, played etc. \n",
        "\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "df['Text'] = df['Text'].apply(lambda x: [stemmer.stem(i) for i in x.split()]) # stemming\n",
        "df['Text'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [sale, boost, time, warner, profit, quarterli,...\n",
              "1    [dollar, gain, greenspan, speech, dollar, high...\n",
              "2    [yuko, unit, buyer, face, loan, claim, owner, ...\n",
              "3    [high, fuel, price, profit, british, airway, b...\n",
              "4    [pernod, takeov, talk, lift, domecq, share, dr...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIB4JjSh3l-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].apply( lambda x: ' '.join(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaDTreY57roa",
        "colab_type": "code",
        "outputId": "e16ba3c2-e42c-447a-a5ae-23b68e2ae50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sale boost time warner profit quarterli profit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dollar gain greenspan speech dollar highest le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yuko unit buyer face loan claim owner embattl ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>high fuel price profit british airway blame hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pernod takeov talk lift domecq share drink foo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Label\n",
              "0  sale boost time warner profit quarterli profit...      0\n",
              "1  dollar gain greenspan speech dollar highest le...      0\n",
              "2  yuko unit buyer face loan claim owner embattl ...      0\n",
              "3  high fuel price profit british airway blame hi...      0\n",
              "4  pernod takeov talk lift domecq share drink foo...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYLPArdG7vE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using Keras preprocessing functions for preparing the input dataset\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#tokenizing the processed text again\n",
        "tk = Tokenizer(lower = True)\n",
        "tk.fit_on_texts(df['Text'])               \n",
        "\n",
        "#representing the word by a number equal to the frequency of its occcurence.\n",
        "X_seq = tk.texts_to_sequences(df['Text'])   \n",
        "\n",
        "#limiting the length of each sentence to 100. Padding with 0 if sentence is short\n",
        "X_pad = pad_sequences(X_seq, maxlen=100, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvtv73948726",
        "colab_type": "code",
        "outputId": "d9d742cb-71c9-4e98-927d-654467e53d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYAiHf2O8YE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Binarizing the output label i.e. representing each label in binary format\n",
        "\n",
        "from sklearn import preprocessing\n",
        "y = df['Label']\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y)\n",
        "m = lb.transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdkIv5GQ8z5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing train and test datasets\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X_pad, m, y  = shuffle(X_pad, m, y, random_state = 0)\n",
        "X_train = X_pad[:-800]\n",
        "X_test  = X_pad[-800:]\n",
        "y_train = m[:-800]\n",
        "y_test = m[-800:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1vd4R13-QZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  vocabulary_size = len(tk.word_counts.keys())+1\n",
        "  max_words = 100\n",
        "  embedding_size = 32\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(100, kernel_size=8, activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=4))\n",
        "  model.add(LSTM(200,return_sequences=True))\n",
        "  model.add(LSTM(200))\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9SsDs8h-W0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODdjJnOj-xG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azJLjtst-20N",
        "colab_type": "code",
        "outputId": "b82b47a6-a365-46f5-dd46-6d5c0d494768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input, Lambda\n",
        "\n",
        "results = cross_val_score(estimator, X_pad, y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 06:17:52.324379 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0731 06:17:52.369434 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 06:17:52.381415 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0731 06:17:52.403284 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0731 06:17:52.413901 140380433893248 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0731 06:17:52.483482 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0731 06:17:53.280529 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0731 06:17:53.304310 140380433893248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0731 06:17:53.479383 140380433893248 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Baseline: 87.14% (4.22%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSGUrCfssLbP",
        "colab_type": "code",
        "outputId": "5ac3a721-6e5b-4fd0-f06c-f0dc2fc2e738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# using confusion matrix\n",
        "model = create_model()\n",
        "\n",
        "clf = model.fit(X_train, y_train, epochs = 30, batch_size = 500)\n",
        "\n",
        "out = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1425/1425 [==============================] - 7s 5ms/step - loss: 1.6064 - acc: 0.2225\n",
            "Epoch 2/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 1.6021 - acc: 0.2604\n",
            "Epoch 3/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 1.5904 - acc: 0.3060\n",
            "Epoch 4/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 1.5723 - acc: 0.4042\n",
            "Epoch 5/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 1.4965 - acc: 0.4449\n",
            "Epoch 6/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 1.2207 - acc: 0.4540\n",
            "Epoch 7/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.9868 - acc: 0.5551\n",
            "Epoch 8/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.8240 - acc: 0.6323\n",
            "Epoch 9/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.6222 - acc: 0.6961\n",
            "Epoch 10/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.4393 - acc: 0.8568\n",
            "Epoch 11/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.2613 - acc: 0.9025\n",
            "Epoch 12/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.1325 - acc: 0.9572\n",
            "Epoch 13/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0914 - acc: 0.9698\n",
            "Epoch 14/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0358 - acc: 0.9902\n",
            "Epoch 15/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0194 - acc: 0.9951\n",
            "Epoch 16/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0086 - acc: 0.9986\n",
            "Epoch 17/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0077 - acc: 0.9979\n",
            "Epoch 18/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 19/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 20/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 21/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 22/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0019 - acc: 0.9993\n",
            "Epoch 23/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 24/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.9986\n",
            "Epoch 25/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 4.8516e-04 - acc: 1.0000\n",
            "Epoch 26/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 4.4940e-04 - acc: 1.0000\n",
            "Epoch 27/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 4.2239e-04 - acc: 1.0000\n",
            "Epoch 28/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 4.0636e-04 - acc: 1.0000\n",
            "Epoch 29/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 3.8317e-04 - acc: 1.0000\n",
            "Epoch 30/30\n",
            "1425/1425 [==============================] - 4s 3ms/step - loss: 3.7606e-04 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIcns4x-srM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#The predicted output will be floating point values and must be rounded to the nearest integers\n",
        "\n",
        "out1 = np.round(out)\n",
        "k = out1.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g8P5kBs0mT",
        "colab_type": "code",
        "outputId": "25490e0a-2acf-4354-e2fb-26a14da54352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "multilabel_confusion_matrix(y_test, k, labels = [0,1,2,3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[607,  15],\n",
              "        [ 12, 166]],\n",
              "\n",
              "       [[647,  13],\n",
              "        [ 20, 120]],\n",
              "\n",
              "       [[632,  15],\n",
              "        [ 20, 133]],\n",
              "\n",
              "       [[603,  11],\n",
              "        [  9, 177]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLVKEMb7xc6U",
        "colab_type": "text"
      },
      "source": [
        "classification accuracy is 90 percent"
      ]
    }
  ]
}